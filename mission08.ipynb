{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bf326f",
   "metadata": {},
   "source": [
    "# 미션 08\n",
    "## Football (Semantic Segmentation)\n",
    "U-Net을 이용해 축구 경기 영상 내의 다양한 객체(예: 골대, 심판, 선수, 관중 등)를 픽셀 단위로 분할하는 Semantic Segmentation 작업을 수행합니다\n",
    "\n",
    "11개 클래스\n",
    "- Goal Bar (골대)\n",
    "- Referee (심판)\n",
    "- Advertisement (광고판)\n",
    "- Ground (잔디)\n",
    "- Ball (축구공)\n",
    "- Coaches & Officials (코칭 스태프 및 심판진)\n",
    "- Audience (관중)\n",
    "- Goalkeeper A (팀 A 골키퍼)\n",
    "- Goalkeeper B (팀 B 골키퍼)\n",
    "- Team A (팀 A 선수)\n",
    "- Team B (팀 B 선수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890c4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from typing import List, Tuple, Dict, Callable, Optional\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import json\n",
    "import albumentations as A\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"sadhliroomyprime/football-semantic-segmentation\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace922e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: /mnt/d/data/2025/Part2/misson/misson08\n",
      "Notebook file (approx): /mnt/d/data/2025/Part2/misson/misson08\n",
      "Listing CWD files: ['archive.zip', 'class_performance.png', 'color_mapping.json', 'data', 'football_unet_best.pt', 'mission08.ipynb', 'overlay.png', 'predictions.png', '[스프린트미션]8_Image+Segmentation.ipynb']\n",
      "zip_file_path (given): ./archive.zip\n",
      "absolute path -> /mnt/d/data/2025/Part2/misson/misson08/archive.zip\n",
      "exists? True\n",
      "is file? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Notebook file (approx):\", Path().resolve())   # 보통 커널의 CWD\n",
    "print(\"Listing CWD files:\", os.listdir('.'))\n",
    "\n",
    "zip_file_path = './archive.zip'\n",
    "print(\"zip_file_path (given):\", zip_file_path)\n",
    "print(\"absolute path ->\", os.path.abspath(zip_file_path))\n",
    "print(\"exists?\", os.path.exists(zip_file_path))\n",
    "print(\"is file?\", os.path.isfile(zip_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a8ef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./data/'에 이미 파일이 있습니다. 압축 풀기를 건너뜁니다.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 압축 파일 풀기\n",
    "# ============================================\n",
    "\n",
    "# 압축할 zip 파일 경로\n",
    "zip_file_path = './archive.zip'\n",
    "# 압축 풀고 싶은 디렉토리 경로\n",
    "extract_path = './data/'\n",
    "\n",
    "# 이미 압축이 있다면 건너뛰기\n",
    "if os.path.exists(extract_path) and os.listdir(extract_path):\n",
    "    print(f\"'{extract_path}'에 이미 파일이 있습니다. 압축 풀기를 건너뜁니다.\")\n",
    "else:\n",
    "    # extract_path 디렉토리가 없으면 생성\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.makedirs(extract_path)\n",
    "    # zip 파일 열기\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # 지정한 경로에 모든 파일 압축 풀기\n",
    "        zip_ref.extractall(extract_path)\n",
    "        print(f\"'{zip_file_path}' 파일이 '{extract_path}'에 성공적으로 풀렸습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab96d6",
   "metadata": {},
   "source": [
    "### 전체 흐름 요약\n",
    "\n",
    "1. 데이터 준비 – 폴더 안의 이미지와 마스크를 매칭해 image_pairs 리스트에 저장합니다.\n",
    "2. 시각화 – 몇 개의 원본·마스크 쌍을 화면에 띄워 데이터가 올바르게 매칭됐는지 확인합니다.\n",
    "3. 클래스 매핑 – 마스크에 쓰인 고유 RGB 색상을 수집해 color_to_label 딕셔너리를 만듭니다.\n",
    "4. Dataset 정의 – FootballDataset 클래스에서 이미지·마스크를 읽어 정규화하고, RGB 마스크를 정수 클래스 인덱스로 변환합니다.\n",
    "5. DataLoader – 학습·검증용 데이터 로더를 생성합니다.\n",
    "6. 모델 정의 – U‑Net 구조를 UNet 클래스에 구현합니다.\n",
    "7. 학습 루프 – Cross‑Entropy 로스를 계산해 가중치를 업데이트합니다.\n",
    "8. 검증 및 시각화 – 테스트 세트에서 예측한 마스크를 원본 이미지와 정답 마스크와 함께 화면에 표시합니다.\n",
    "\n",
    "아래에서 각 단계별 핵심 코드를 한 줄씩 짚어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6f722",
   "metadata": {},
   "source": [
    "## PART 1: 모든 함수/클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155aa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 데이터셋 전체의 고유한 색상 수집\n",
    "# ============================================\n",
    "\n",
    "def get_unique_colors(image_folder, mask_files, max_classes=11, ignore_color=None, verbose=False):\n",
    "    \"\"\"\n",
    "    마스크 이미지에서 사용된 고유 RGB 색을 추출하고, (R,G,B) 튜플 목록을 반환한다.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): 마스크 파일이 들어있는 파일 경로\n",
    "        mask_files (str) : 마스크 파일명 리스트 (예. Frame 1  (4).jpg___fuse.png)\n",
    "        max_classes (int, optional): _description_. Defaults to 11.\n",
    "        ignore_color (List[Tuple[int,int,int]]) : 무시할 색 (예. 배경색) 지정하면 해당 색은 집합에 추가되지 않는다.\n",
    "        verbose (bool) : 진행 상황을 콘솔에 출력\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int,int,int]]\n",
    "            정렬된 고유 색 목록. (R,G,B) 형태 튜플이며,\n",
    "            (R,G,B) 순서로 정렬되어 매 실행마다 동일한 순서를 보장한다.\n",
    "    \"\"\"\n",
    "    # 초기 설정\n",
    "    ignore_set = set(ignore_color or [])\n",
    "    color_set = set()\n",
    "    \n",
    "    # 파일 순회\n",
    "    for i, mask_file in enumerate(mask_files):\n",
    "        mask_path = os.path.join(image_folder, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f'[get_unique_colors] 마스크를 읽을 수 없습니다.: {mask_path}')\n",
    "        \n",
    "        # BGR -> RGB\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 고유 색 추출\n",
    "        unique_colors = np.unique(mask.reshape(-1, 3), axis=0)\n",
    "        \n",
    "        # 색을 집합에 추가 (ignore 색 제외)\n",
    "        for color in unique_colors:\n",
    "            color_tuple = tuple(int(c) for c in color) # numpy scalar -> 파이썬 int\n",
    "            if color_tuple in ignore_set:\n",
    "                continue\n",
    "            color_set.add(tuple(color))  # 고유한 색상 저장\n",
    "\n",
    "            # 클래스 개수가 max_classes개가 되면 중단\n",
    "            if len(color_set) >= max_classes:\n",
    "                if verbose:\n",
    "                    print(f\"[get_unique_colors] {max_classes}개의 고유 색을 찾았으므로 탐색 종료 (파일 #{i+1}/{len(mask_files)})\")\n",
    "                break\n",
    "            if verbose and (i + 1) % 100 == 0:  # 100 파일마다 진행 상황\n",
    "                print(f\"[get_unique_colors] {i+1}/{len(mask_files)} 파일 처리 → 현재 색 개수: {len(color_set)}\")\n",
    "    \n",
    "    # 정렬 & 반환 (R->G->B 순서로 Deterministic 정렬)           \n",
    "    sorted_colors = sorted(color_set, key=lambda c: (c[0], c[1], c[2]))\n",
    "    if verbose:\n",
    "        print(f\"[get_unique_colors] 최종 고유 색 개수: {len(sorted_colors)} (예시: {sorted_colors[:5]})\")\n",
    "    return sorted_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c68d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 pairs\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 데이터 파일 로딩 & 매칭\n",
    "# ============================================\n",
    "\n",
    "# 폴더 내 모든 파일 목록 가져오기\n",
    "image_folder = os.path.join(extract_path, \"images\")\n",
    "file_list = os.listdir(image_folder)\n",
    "\n",
    "# 원본 이미지(.jpg)와 fuse 이미지 매칭\n",
    "original_files = sorted([f for f in file_list if f.endswith(\".jpg\")])\n",
    "fuse_files = sorted([f for f in file_list if \"fuse\" in f])\n",
    "\n",
    "# 이미지 로드 및 확인\n",
    "image_pairs = []\n",
    "for orig_file in original_files:\n",
    "    # 동일한 프레임의 fuse 파일 찾기\n",
    "    base_name = orig_file.replace(\".jpg\", \"\")\n",
    "    fuse_file = next((f for f in fuse_files if base_name in f), None)\n",
    "\n",
    "    if fuse_file:\n",
    "        # 원본과 마스크 로드\n",
    "        img_path = os.path.join(image_folder, orig_file)\n",
    "        mask_path = os.path.join(image_folder, fuse_file)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "\n",
    "        if img is not None and mask is not None:\n",
    "            image_pairs.append((img, mask))\n",
    "\n",
    "# 최종적으로 로드된 이미지 쌍 개수 출력\n",
    "print(f\"{len(image_pairs)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95256e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 색상 매핑 JSON 저장 / 로드 함수\n",
    "# ============================================\n",
    "\n",
    "def save_color_mapping(color_to_label, filepath='color_mapping.json'):\n",
    "    \"\"\"\n",
    "    color_to_label 을 JSON 파일로 저장\n",
    "\n",
    "    Args:\n",
    "        color_to_label (dict): {(R,G,B): label_idx} 매핑\n",
    "        filepath (str): 저장할 JSON 파일 경로\n",
    "    \"\"\"\n",
    "    \n",
    "    # 튜플 키를 문자열로 변환 (JSON 은 튜플 키를 지원하지 않음)\n",
    "    color_to_label_str = {str(color): label for color, label in color_to_label.items()}\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(color_to_label_str, f, indent=2)\n",
    "    print(f\"색상 매핑이 '{filepath}'에 저장되었습니다.\")\n",
    "\n",
    "def load_color_mapping(filepath='color_mapping.json'):\n",
    "    \"\"\"\n",
    "    JSON 에서 color_to_label 을 불러옴\n",
    "    \n",
    "    Args:\n",
    "        dict: {(R,G,B): label_idx} 매핑\n",
    "    \"\"\"\n",
    "    with open(filepath,'r') as f:\n",
    "        color_to_label_str = json.load(f)\n",
    "        \n",
    "    # 문자열 키를 다시 튜플로 변환\n",
    "    # \"(255, 0, 0)\" -> (255, 0, 0)\n",
    "    color_to_label = {}\n",
    "    for color_str, label in color_to_label_str.items():\n",
    "        # 문자열을 튜플로 변환\n",
    "        color_tuple = eval(color_str) # \"(255, 0, 0)\" -> (255, 0, 0)\n",
    "        color_to_label[color_tuple] = label\n",
    "        \n",
    "    print(f\"'{filepath}'에서 {len(color_to_label)}개의 색상 매핑을 불러왔습니다.\")\n",
    "    return color_to_label\n",
    "\n",
    "def get_or_create_color_mapping(image_folder, fuse_file,\n",
    "                                filepath='color_mapping.json',\n",
    "                                max_classes=11,\n",
    "                                ignore_color=None,\n",
    "                                force_create=False):\n",
    "    \"\"\"\n",
    "    JSON 파일이 있으면 불러오고, 없으면 생성해서 저장\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): 이미지 폴더 경로\n",
    "        fuse_files (list): 마스크 파일 리스트\n",
    "        filepath (str): JSON 파일 경로\n",
    "        max_classes (int): 최대 클래스 수\n",
    "        ignore_color (list): 무시할 색상\n",
    "        force_create (bool): True면 기존 파일 무시하고 새로 생성\n",
    "        \n",
    "    Returns:\n",
    "        dict : {(R,G,B): label_idx} 매핑\n",
    "    \"\"\"\n",
    "    \n",
    "    # 파일이 존재하고 force_create 가 False 이면 불러오기\n",
    "    if os.path.exists(filepath) and not force_create:\n",
    "        print(f\"기존 색상 매핑 파일 발견 : '{filepath}'\")\n",
    "        color_to_label = load_color_mapping(filepath)\n",
    "        return color_to_label\n",
    "    \n",
    "    # 파일이 없거나 force_create=True 면 새로 생성\n",
    "    print(\"색상 매핑 파일이 없습니다. 새로 생성합니다...\")\n",
    "    print(\"(이 작업은 시간이 걸릴 수 있습니다)\")\n",
    "    unique_colors = get_unique_colors(\n",
    "        image_folder, fuse_files,\n",
    "        max_classes=max_classes,\n",
    "        ignore_color = ignore_color,\n",
    "        verbose=True)\n",
    "    \n",
    "    color_to_label = {color : idx for idx, color in enumerate(unique_colors)}\n",
    "    \n",
    "    # JSON 으로 저장\n",
    "    save_color_mapping(color_to_label, filepath)\n",
    "    \n",
    "    return color_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019eb95",
   "metadata": {},
   "source": [
    "### U-Net 세그멘테이션 데이터 증강(Augmentation)\n",
    "시맨틱 세그멘테이션 (Semantic Segmentation) 모델인 U-Net 을 학습할 때도 **데이터 증강은 적극적으로 권장** 됩니다.\n",
    "\n",
    "증강이 필요한 이유\n",
    "- **일반화 능력 향상** : 모델이 다양한 환경(각도, 크기, 위치) 의 객체를 인식하도록 훈련하는 **오버피팅(Overfitting)을 방지** 하고 실제 환경에서의 성능을 높입니다.\n",
    "- **데이터 부족 해소** : 세그멘테이션 데이터셋은 구축이 어렵고 양이 적은 경우가 많습니다. 증강은 사실상 **데이터의 양을 늘리는 효과** 를 가져옵니다.\n",
    "\n",
    "#### ※ 주의 사항: **이미지와 마스크 동시 적용**\n",
    "\n",
    "세그멘테이션에서 가장 중요한 점은 원본 이미지와 정답 마스크(Ground Truth Mask)에 동일한 변형을 동시에 적용해야 한다는 것입니다.\n",
    "\n",
    "`FootballDataset` 클래스에 이를 위한 구조가 마련하였습니다.\n",
    "```python\n",
    "# FootballDataset 클래스 __init__ 내부\n",
    "transform: Optional[Callable[[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]]] = None,\n",
    "\n",
    "# __getitem__ 메서드 내부\n",
    "if self.transform is not None:\n",
    "    img_tensor, mask_tensor = self.transform(img_tensor, mask_tensor)\n",
    "```\n",
    "따라서 `transform` 함수를 구현할때 입력으로 이미지 텐서와 마스크 텐서를 동시에 받아 두 Tensor에 동일한 기하학적 변형을 적용하고 반환하도록 구현하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Dataset 클래스 정의 (RGB 마스크 변환 포함)\n",
    "# ============================================\n",
    "    \n",
    "class FootballDataset(Dataset):\n",
    "    \"\"\"\n",
    "    - 이미지 + RGB 마스크를 로드하고,\n",
    "    - 사전에 정의된 `color_to_lable` 로 RGB 마스크를 정수 라벨로 변환\n",
    "    - `transform` 함수를 통해 이미지·마스크 동시 전처리를 지원\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 image_files: List[str],\n",
    "                 mask_files: List[str],\n",
    "                 image_folder:str,\n",
    "                 color_to_label : Dict[Tuple[int,int,int],int],\n",
    "                 transform : None, #Optional[Callable[[torch.Tensor,torch.Tensor], Tuple[torch.Tensor,torch.Tensor]]]=None,\n",
    "                 target_size: Tuple[int,int] = (256,256),\n",
    "                 ignore_colors : Optional[List[Tuple[int, int, int]]] = None,\n",
    "                 verify_mapping : bool = True,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_files , mask_files (List)\n",
    "                : 같은 인덱스끼리 짝을 이루는 파일명 리스트\n",
    "                (예. [Frame 1  (6).jpg], [Frame 1  (6).jpg___fuse.png])\n",
    "            image_folder (str)\n",
    "                : 두 리스트에 있는 파일이 모두 들어 있는 디렉터리\n",
    "            color_to_label (dict)\n",
    "                :(R,G,B) 튜플 -> 라벨 정수 매핑 0~N~1 로 연속되어야 함\n",
    "            transform \n",
    "                : Train , Test 마다 transform 각각 선언\n",
    "            target_size (W,H)\n",
    "                : 모든 이미지·마스크를  `cv2.resize` 로 맞출 크기\n",
    "            ignore_colors (list of tuple, optional)\n",
    "                : 라벨링에 쓰지 않을 색(예. 배경) 해당 픽셀은 -1 로 마킹\n",
    "            verify_mapping (bool)\n",
    "                : `True` 모든 마스크에 등장하는 색이 `color_to_label` 혹은\n",
    "                `ignore_colors` 에 포함되는지 검사하고, 누락 시 `ValueError` 를 발생 시킵니다.\n",
    "        \"\"\"\n",
    "        assert len(image_files) == len(mask_files),\\\n",
    "            \"이미지 파일 수와 마스크 파일 수가 다릅니다.\"\n",
    "        \n",
    "        # 파일 리스트를 반드시 정렬해 동일 인덱스가 같은 프레일을 가리키게 합니다.\n",
    "        self.image_files = sorted(image_files)\n",
    "        self.mask_files = sorted(mask_files)\n",
    "        self.image_folder = image_folder\n",
    "        self.color_to_label = color_to_label  # 고정된 클래스 매핑\n",
    "        self.transform = transform\n",
    "        self.target_w, self.target_h = target_size\n",
    "        self.ignore_colors = ignore_colors or []\n",
    "        self.LUT = self._create_lut() \n",
    "        \n",
    "        if verify_mapping:\n",
    "            self._verify_all_colors()\n",
    "            \n",
    "    def _create_lut(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        색상 매핑 LUT를 한번만 생성\n",
    "\n",
    "        Returns:\n",
    "            2^24 크기의 LUT (모든 RGB 조합 커버)\n",
    "        \"\"\"\n",
    "        #  매핑 테이블을 2-D 배열(65536*256) 으로 만든 뒤 색을 라벨 인덱싱\n",
    "        # (8 bit per channel -> 전체 2**24 개의 경우의 수 이므로 메모리가 허용됨)\n",
    "        LUT = np.full(2**24, fill_value=-1, dtype=np.int64)  # 기본 -1\n",
    "        \n",
    "        for rgb, lbl in self.color_to_label.items():\n",
    "            key = (rgb[0] << 16) | (rgb[1] << 8) | rgb[2]\n",
    "            LUT[key] = lbl\n",
    "            \n",
    "        for rgb, lbl in self.ignore_colors:\n",
    "            key = (rgb[0] << 16) | (rgb[1] << 8) | rgb[2]\n",
    "            LUT[key] = -1\n",
    "            \n",
    "        return LUT\n",
    "            \n",
    "    # 클래스 검증 (디버깅용)\n",
    "    def _verify_all_colors(self):\n",
    "            \"\"\"모든 마스크 색상 검증\"\"\"\n",
    "            known_colors = set(self.color_to_label.keys())\n",
    "            known_colors.update(self.ignore_colors)\n",
    "            \n",
    "            for mask_file in self.mask_files:\n",
    "                mask_path = os.path.join(self.image_folder, mask_file)\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "                if mask is None:\n",
    "                    raise FileNotFoundError(f\"Mask 파일 없음: {mask_path}\")\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "                uniq = np.unique(mask.reshape(-1, 3), axis=0)\n",
    "                \n",
    "                for c in uniq:\n",
    "                    tup = tuple(int(v) for v in c)\n",
    "                    if tup not in known_colors:\n",
    "                        raise ValueError(\n",
    "                            f\"mask {mask_file}에 알 수 없는 색 {tup}\"\n",
    "                        )\n",
    "    \n",
    "    def __len__(self)->int:\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # 이미지, 마스크 경로\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.image_folder, self.mask_files[idx])\n",
    "\n",
    "        # 원본 이미지 로드 & 전처리\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR) # BGR\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image 파일을 찾을 수 없습니다: {img_path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (self.target_w, self.target_h), # (W,H)\n",
    "                         interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # 마스크 로드\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Mask 파일을 찾을 수 없습니다. : {mask_path}\")\n",
    "        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.resize(mask, (self.target_w, self.target_h),\n",
    "                          interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Albumentations 적용 (Tensor 변환 전)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        \n",
    "        # LUT를 사용한 빠른 변환 (매번 LUT 생성 X)\n",
    "        packed = (mask[..., 0].astype(np.uint32) << 16) | \\\n",
    "                 (mask[..., 1].astype(np.uint32) << 8) | \\\n",
    "                 (mask[..., 2].astype(np.uint32))\n",
    "        label_mask = self.LUT[packed]\n",
    "\n",
    "        # (optional) unknown 색(-1) 가 있으면 0(배경) 으로 바꾸거나 에러를 낼 수 있음\n",
    "        if np.any(label_mask == -1):\n",
    "            # 여기서는 0(배경) 로 대체. 필요시 raise 로 변경.\n",
    "            label_mask[label_mask == -1] = 0\n",
    "\n",
    "        # float32 로 변환 + [0,1] 정규화\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # ----- torch Tensor 로 변환 ----- #\n",
    "        # 이미지: (H,W, C) → (C, H, W) , float32\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).contiguous()\n",
    "        # 마스크: (H, W) , int64 (CrossEntropyLoss 가 요구하는 타입)\n",
    "        mask_tensor = torch.from_numpy(label_mask).long()\n",
    "\n",
    "        return img_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a997174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# U-Net 모델 정의\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2d -> BatchNorm -> ReLU) x 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling: MaxPool -> DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling: Upsample -> Concat -> DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, \n",
    "                                     kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # x2의 크기에 맞춰 x1 패딩 (필요시)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                       diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net 모델\n",
    "    \n",
    "    Args:\n",
    "        n_channels: 입력 이미지 채널 수 (RGB: 3)\n",
    "        n_classes: 출력 클래스 수 (11개)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=11):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder (Contracting Path)\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        \n",
    "        # Decoder (Expanding Path)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)      # 64 channels\n",
    "        x2 = self.down1(x1)   # 128 channels\n",
    "        x3 = self.down2(x2)   # 256 channels\n",
    "        x4 = self.down3(x3)   # 512 channels\n",
    "        x5 = self.down4(x4)   # 1024 channels\n",
    "        \n",
    "        # Decoder (skip connections)\n",
    "        x = self.up1(x5, x4)  # 512 channels\n",
    "        x = self.up2(x, x3)   # 256 channels\n",
    "        x = self.up3(x, x2)   # 128 channels\n",
    "        x = self.up4(x, x1)   # 64 channels\n",
    "        \n",
    "        # Output\n",
    "        logits = self.outc(x) # n_classes channels\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 학습 함수 (Semantic Segmentation용)\n",
    "# ============================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early Stopping (mIoU기반)\"\"\"\n",
    "    def __init__(self, patience=5, verbose=True, delta=0.0, path=\"bast_model.pt\"):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "        \n",
    "    def __call__(self, val_miou, model):\n",
    "        score = val_miou\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"Early Stopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        if self.verbose:\n",
    "            print(f\"Validation mIoU increased ({self.best_score:.4f}). Saving model...\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, target, num_classes):\n",
    "    \"\"\"\n",
    "    Pixel Accuracy, mIoU, Dice Score 계산\n",
    "    \n",
    "    Args:\n",
    "        pred: (B, H, W) - 예측 클래스 인덱스\n",
    "        target: (B, H, W) - 실제 클래스 인덱스\n",
    "        num_classes: 클래스 개수\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'pixel_acc', 'miou', 'dice', 'class_ious'}\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "    \n",
    "    # Pixel Accuracy\n",
    "    correct = (pred == target).sum()\n",
    "    total = target.size\n",
    "    pixel_acc = correct / total\n",
    "    \n",
    "    # IoU per class\n",
    "    ious = []\n",
    "    class_ious = {}\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        target_cls = (target == cls)\n",
    "        \n",
    "        intersection = (pred_cls & target_cls).sum()\n",
    "        union = (pred_cls | target_cls).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = float('nan')  # 해당 클래스가 없음\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        \n",
    "        class_ious[f'class_{cls}'] = iou\n",
    "        if not np.isnan(iou):\n",
    "            ious.append(iou)\n",
    "    \n",
    "    # mIoU (평균 IoU)\n",
    "    miou = np.mean(ious) if len(ious) > 0 else 0.0\n",
    "    \n",
    "    # Dice Score (F1-Score와 동일)\n",
    "    intersection_total = (pred == target).sum()\n",
    "    dice = 2 * intersection_total / (pred.size + target.size)\n",
    "    \n",
    "    return {\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'miou': miou,\n",
    "        'dice': dice,\n",
    "        'class_ious': class_ious\n",
    "    }\n",
    "    \n",
    "    \n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, num_classes):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for images, masks in tqdm(train_loader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)  # (B, C, H, W)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 예측 (배치별로 저장)\n",
    "        preds = torch.argmax(outputs, dim=1)  # (B, H, W)\n",
    "        all_preds.append(preds.detach())\n",
    "        all_targets.append(masks)\n",
    "    \n",
    "    # 전체 배치 합치기\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = calculate_metrics(all_preds, all_targets, num_classes)\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "        \n",
    "        \n",
    "def validate_epoch(model, val_loader, criterion, device, num_classes):\n",
    "    \"\"\"검증\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(masks)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    metrics = calculate_metrics(all_preds, all_targets, num_classes)\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, num_classes):\n",
    "    \"\"\"검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(masks)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    metrics = calculate_metrics(all_preds, all_targets, num_classes)\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_classes, device,\n",
    "                num_epochs=50, lr=0.001, patience=7, model_name='unet'):\n",
    "    \"\"\"\n",
    "    전체 학습 파이프라인\n",
    "    \n",
    "    Args:\n",
    "        model: U-Net 모델\n",
    "        train_loader, val_loader: DataLoader\n",
    "        num_classes: 클래스 개수\n",
    "        device: cuda/cpu\n",
    "        num_epochs: 최대 에포크 수\n",
    "        lr: 학습률\n",
    "        patience: Early Stopping patience\n",
    "        model_name: 모델 저장 이름\n",
    "    \n",
    "    Returns:\n",
    "        model: 학습된 모델\n",
    "        history: 학습 히스토리\n",
    "    \"\"\"\n",
    "    # Loss & Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stopper = EarlyStopping(\n",
    "        patience=patience,\n",
    "        verbose=True,\n",
    "        path=f'{model_name}_best.pt'\n",
    "    )\n",
    "    \n",
    "    # History\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_miou': [],\n",
    "        'train_pixel_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_miou': [],\n",
    "        'val_pixel_acc': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, num_classes\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_metrics = validate_epoch(\n",
    "            model, val_loader, criterion, device, num_classes\n",
    "        )\n",
    "        \n",
    "        # 히스토리 저장\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_miou'].append(train_metrics['miou'])\n",
    "        history['train_pixel_acc'].append(train_metrics['pixel_acc'])\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_miou'].append(val_metrics['miou'])\n",
    "        history['val_pixel_acc'].append(val_metrics['pixel_acc'])\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"Train Loss: {train_loss:.4f} | mIoU: {train_metrics['miou']:.4f} | Pixel Acc: {train_metrics['pixel_acc']:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | mIoU: {val_metrics['miou']:.4f} | Pixel Acc: {val_metrics['pixel_acc']:.4f}\")\n",
    "        \n",
    "        # Learning Rate 조정\n",
    "        scheduler.step(val_metrics['miou'])\n",
    "        \n",
    "        # Early Stopping\n",
    "        if early_stopper(val_metrics['miou'], model):\n",
    "            print(f\"Early Stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"\\n총 학습 시간: {train_time/60:.2f}분\")\n",
    "    \n",
    "    # 최고 모델 로드\n",
    "    model.load_state_dict(torch.load(f'{model_name}_best.pt'))\n",
    "    print(\"최고 성능 모델 로드 완료\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c218dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Class Weight 계산 (배경 클래스에 낮은 가중치)\n",
    "# ============================================\n",
    "\n",
    "def calculate_class_weights(train_loader, num_classes, device):\n",
    "    \"\"\"클래스 빈도에 따른 가중치 계산\"\"\"\n",
    "    class_counts = torch.zeros(num_classes)\n",
    "    \n",
    "    for _, masks in train_loader:\n",
    "        for c in range(num_classes):\n",
    "            class_counts[c] += (masks == c).sum().item()\n",
    "    \n",
    "    total = class_counts.sum()\n",
    "    class_weights = total / (num_classes * class_counts)\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "    \n",
    "    return class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 모델 불러오기\n",
    "# ============================================\n",
    "\n",
    "def load_trained_model(model_path, num_classes, device='cuda'):\n",
    "    \"\"\"\n",
    "    저장된 모델 가중치 불러오기\n",
    "    \n",
    "    Args:\n",
    "        model_path: 저장된 모델 파일 경로 (예: 'football_unet_best.pt')\n",
    "        num_classes: 클래스 개수\n",
    "        device: 'cuda' 또는 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        model: 불러온 모델\n",
    "    \"\"\"\n",
    "    # 디바이스 설정\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 모델 구조 생성\n",
    "    model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "    \n",
    "    # 가중치 로드\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"모델 파일을 찾을 수 없습니다: {model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()  # 평가 모드로 설정\n",
    "    \n",
    "    print(f\"모델 로드 완료: {model_path}\")\n",
    "    print(f\"디바이스: {device}\")\n",
    "    print(f\"클래스 개수: {num_classes}\")\n",
    "    \n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8f9ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f880a1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51196353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 전체 데이터 파이프라인 재구성\n",
    "# ============================================\n",
    "\n",
    "def setup_inference_pipeline(\n",
    "    data_path='./data/images',\n",
    "    color_mapping_path='color_mapping.json',\n",
    "    model_path='football_unet_best.pt'\n",
    "):\n",
    "    \"\"\"\n",
    "    추론을 위한 전체 파이프라인 설정\n",
    "    \n",
    "    Returns:\n",
    "        model, device, color_to_label, test_loader, label_to_color\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"추론 파이프라인 설정 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. 색상 매핑 로드\n",
    "    print(\"\\n1. 색상 매핑 로드...\")\n",
    "    color_to_label = load_color_mapping(color_mapping_path)\n",
    "    num_classes = len(color_to_label)\n",
    "    \n",
    "    # 라벨 -> 색상 역매핑 (시각화용)\n",
    "    label_to_color = {v: k for k, v in color_to_label.items()}\n",
    "    \n",
    "    # 2. 모델 로드\n",
    "    print(\"\\n2. 모델 로드...\")\n",
    "    model, device = load_trained_model(model_path, num_classes)\n",
    "    \n",
    "    # 3. 데이터 로드\n",
    "    print(\"\\n3. 데이터 로드...\")\n",
    "    image_folder = data_path\n",
    "    file_list = os.listdir(image_folder)\n",
    "    \n",
    "    original_files = sorted([f for f in file_list if f.endswith(\".jpg\")])\n",
    "    fuse_files = sorted([f for f in file_list if \"fuse\" in f])\n",
    "    \n",
    "    print(f\"   원본 이미지: {len(original_files)}개\")\n",
    "    print(f\"   마스크 이미지: {len(fuse_files)}개\")\n",
    "    \n",
    "    # 4. Dataset 생성\n",
    "    print(\"\\n4. Dataset 생성...\")\n",
    "    test_dataset = FootballDataset(\n",
    "        image_files=original_files,\n",
    "        mask_files=fuse_files,\n",
    "        image_folder=image_folder,\n",
    "        color_to_label=color_to_label,\n",
    "        transform=None,  # 테스트는 증강 없음\n",
    "        target_size=(256, 256),\n",
    "        verify_mapping=False\n",
    "    )\n",
    "    \n",
    "    # 5. DataLoader 생성\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    print(f\"   테스트 데이터: {len(test_dataset)}개\")\n",
    "    print(f\"   배치 수: {len(test_loader)}개\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"파이프라인 설정 완료!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return model, device, color_to_label, test_loader, label_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff721aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 모델 생성 및 확인\n",
    "# ============================================\n",
    "\n",
    "# 클래스 개수 확인\n",
    "num_classes = len(color_to_label)\n",
    "print(f\"클래스 개수: {num_classes}\")\n",
    "\n",
    "# 모델 생성\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 모델 테스트 (dummy input)\n",
    "dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "    print(f\"입력 shape: {dummy_input.shape}\")\n",
    "    print(f\"출력 shape: {output.shape}\")  # (1, num_classes, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 계산\n",
    "class_weights = calculate_class_weights(train_loader, num_classes, device)\n",
    "print(\"클래스 가중치:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 매칭 결과 시각화\n",
    "# ============================================\n",
    "\n",
    "sample_image_pairs = []\n",
    "num_samples = 5\n",
    "\n",
    "for orig_file in original_files[:num_samples]:\n",
    "    base_name = orig_file.replace(\".jpg\", \"\")\n",
    "    fuse_file = next((f for f in fuse_files if base_name in f), None)\n",
    "\n",
    "    if fuse_file:\n",
    "        sample_image_pairs.append((orig_file, fuse_file))\n",
    "\n",
    "# 이미지 5쌍 시각화\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5 * num_samples))\n",
    "\n",
    "for i, (orig_file, fuse_file) in enumerate(sample_image_pairs):\n",
    "    # 이미지 로드\n",
    "    orig_img = cv2.imread(os.path.join(image_folder, orig_file))\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)  # OpenCV BGR → RGB 변환\n",
    "\n",
    "    fuse_img = cv2.imread(os.path.join(image_folder, fuse_file))\n",
    "    fuse_img = cv2.cvtColor(fuse_img, cv2.COLOR_BGR2RGB)  # 마스크도 RGB 변환\n",
    "\n",
    "    # 시각화\n",
    "    axes[i, 0].imshow(orig_img)\n",
    "    axes[i, 0].set_title(f\"Original: {orig_file}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    axes[i, 1].imshow(fuse_img)\n",
    "    axes[i, 1].set_title(f\"Fuse Mask: {fuse_file}\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4520c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 색상 매핑 자동 생성/로드\n",
    "# ============================================\n",
    "\n",
    "# 파일이 있으면 불러오고, 없으면 생성\n",
    "color_to_label = get_or_create_color_mapping(\n",
    "    image_folder=image_folder,\n",
    "    fuse_file=fuse_files,\n",
    "    filepath='color_mapping.json',\n",
    "    max_classes=11,\n",
    "    ignore_color=None,\n",
    "    force_create=False # True 기존 파일 무시하고 새로 생성\n",
    ")\n",
    "\n",
    "print(f\"\\n총 {len(color_to_label)}개의 클래스 발견:\")\n",
    "for color, label in list(color_to_label.items())[:5]:  # 처음 5개만 출력\n",
    "    print(f\"  색상 {color} -> 라벨 {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m pip install --user albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf960f82",
   "metadata": {},
   "source": [
    "원본 이미지와 마스크를 동시에 증강하기 위해 `albumentations` 라이브러리를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa686158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Transform 정의 (Albumentations)\n",
    "# ============================================\n",
    "import albumentations as A\n",
    "# Transform 정의\n",
    "train_transform = A.Compose([\n",
    "    # 기하학적 변환 (이미지 + 마스크 동시)\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.3),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1,\n",
    "        scale_limit = 0.1,\n",
    "        rotate_limit= 10,\n",
    "        p=0.3\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.2,\n",
    "        contrast_limit=0.2,\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=10,\n",
    "        sat_shift_limit=20,\n",
    "        val_shift_limit=10,\n",
    "        p=0.3\n",
    "    ),\n",
    "])\n",
    "\n",
    "test_transform  = None # 증강 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Dataset 생성\n",
    "# ============================================\n",
    "\n",
    "# 증강 적용\n",
    "train_full_dataset = FootballDataset(\n",
    "    image_files=original_files,\n",
    "    mask_files= fuse_files,\n",
    "    image_folder=image_folder,\n",
    "    color_to_label=color_to_label,\n",
    "    transform=train_transform,\n",
    "    target_size=(256,256),\n",
    "    verify_mapping=True\n",
    ")\n",
    "\n",
    "# 증강없음\n",
    "test_full_dataset = FootballDataset(\n",
    "    image_files=original_files,\n",
    "    mask_files=fuse_files,\n",
    "    image_folder=image_folder,\n",
    "    color_to_label=color_to_label,\n",
    "    transform=test_transform,\n",
    "    target_size=(256, 256),\n",
    "    verify_mapping=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4735d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Train/Test 분할\n",
    "# ============================================\n",
    "\n",
    "torch.manual_seed(42)\n",
    "total_size = len(original_files)\n",
    "indices = list(range(total_size))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * total_size)\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_dataset = Subset(train_full_dataset, train_indices)\n",
    "test_dataset = Subset(test_full_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DataLoader 생성\n",
    "# ============================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True,\n",
    "    num_workers=0,pin_memory=True\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False,\n",
    "    num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Train Batches: {len(train_loader)}, Test Batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c903860",
   "metadata": {},
   "source": [
    "## 모델 구조 설명\n",
    "```\n",
    "입력 이미지 (3, 256, 256)\n",
    "    ↓\n",
    "[Encoder]\n",
    "    inc:   (3 → 64)    256×256\n",
    "    down1: (64 → 128)  128×128\n",
    "    down2: (128 → 256) 64×64\n",
    "    down3: (256 → 512) 32×32\n",
    "    down4: (512 → 1024) 16×16\n",
    "    ↓\n",
    "[Decoder + Skip Connections]\n",
    "    up1: (1024 → 512) + skip from down3 → 32×32\n",
    "    up2: (512 → 256)  + skip from down2 → 64×64\n",
    "    up3: (256 → 128)  + skip from down1 → 128×128\n",
    "    up4: (128 → 64)   + skip from inc   → 256×256\n",
    "    ↓\n",
    "출력 (num_classes, 256, 256)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189797f5",
   "metadata": {},
   "source": [
    "미션 7까지 사용하였던 EarlyStopping 을 재사용하기 위해서는\n",
    "\n",
    "`객체 탐지` 였던 클래스에서 `Semantic Segmentation` 으로 바꾸어야 합니다.\n",
    "\n",
    "\n",
    "#### 주요 차이점\n",
    "\n",
    "| 항목 | 객체 탐지 (Object Detection) | 시맨틱 분할 (Semantic Segmentation) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Task** | Bounding Box 예측 | 픽셀별 클래스 예측 |\n",
    "| **출력** | `[{boxes, labels, scores}]` | `(B, C, H, W)` logits (픽셀별 클래스 확률) |\n",
    "| **Loss** | Faster R-CNN 내장 Loss | `Cross Entropy Loss` |\n",
    "| **평가** | mAP (IoU 기반) | Pixel Accuracy, mIoU, Dice |\n",
    "| **입력** | 이미지 리스트 + 타겟 딕셔너리 | 이미지 텐서 + 마스크 텐서 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9400fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 학습 시작\n",
    "# ============================================\n",
    "\n",
    "# 학습 실행\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    num_classes=num_classes,\n",
    "    device=device,\n",
    "    num_epochs=50,\n",
    "    lr=0.001,\n",
    "    patience=7,\n",
    "    model_name='football_unet'\n",
    ")\n",
    "\n",
    "print(\"\\n학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e501ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 실행: 모델 불러오기\n",
    "# ============================================\n",
    "\n",
    "# 전체 파이프라인 설정\n",
    "model, device, color_to_label, test_loader, label_to_color = setup_inference_pipeline(\n",
    "    data_path='./data/images',  # 데이터 경로 수정\n",
    "    color_mapping_path='color_mapping.json',\n",
    "    model_path='football_unet_best.pt'  # 저장한 모델 파일명\n",
    ")\n",
    "\n",
    "print(\"\\n추론 준비 완료! 이제 검증 및 시각화를 진행할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 학습 곡선 시각화 함수\n",
    "# ============================================\n",
    "\n",
    "def plot_training_curves(history, save_path='training_curves.png'):\n",
    "    \"\"\"\n",
    "    학습 히스토리를 시각화\n",
    "    \n",
    "    Args:\n",
    "        history: train_model()에서 반환된 히스토리 딕셔너리\n",
    "        save_path: 저장할 이미지 경로\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # 1. Loss 곡선\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. mIoU 곡선\n",
    "    axes[1].plot(epochs, history['train_miou'], 'b-', label='Train mIoU', linewidth=2)\n",
    "    axes[1].plot(epochs, history['val_miou'], 'r-', label='Val mIoU', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('mIoU', fontsize=12)\n",
    "    axes[1].set_title('Training and Validation mIoU', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Pixel Accuracy 곡선\n",
    "    axes[2].plot(epochs, history['train_pixel_acc'], 'b-', label='Train Pixel Acc', linewidth=2)\n",
    "    axes[2].plot(epochs, history['val_pixel_acc'], 'r-', label='Val Pixel Acc', linewidth=2)\n",
    "    axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[2].set_ylabel('Pixel Accuracy', fontsize=12)\n",
    "    axes[2].set_title('Training and Validation Pixel Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[2].legend(fontsize=11)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"학습 곡선이 '{save_path}'에 저장되었습니다.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fded2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 모델 평가 함수\n",
    "# ============================================\n",
    "\n",
    "def evaluate_model(model, test_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    테스트 데이터셋에 대한 전체 성능 평가\n",
    "    \n",
    "    Returns:\n",
    "        dict: 성능 메트릭 딕셔너리\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"모델 평가 중...\")\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(masks.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    metrics = calculate_metrics(all_preds, all_targets, num_classes)\n",
    "    \n",
    "    return {\n",
    "        'pixel_accuracy': metrics['pixel_acc'],\n",
    "        'miou': metrics['miou'],\n",
    "        'dice': metrics['dice'],\n",
    "        'class_ious': metrics['class_ious']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 클래스별 성능 시각화\n",
    "# ============================================\n",
    "\n",
    "def plot_class_performance(metrics, color_to_label, save_path='class_performance.png'):\n",
    "    \"\"\"\n",
    "    클래스별 IoU 성능 시각화\n",
    "    \n",
    "    Args:\n",
    "        metrics: evaluate_model()에서 반환된 메트릭\n",
    "        color_to_label: 색상-라벨 매핑 딕셔너리\n",
    "        save_path: 저장할 이미지 경로\n",
    "    \"\"\"\n",
    "    class_ious = metrics['class_ious']\n",
    "    \n",
    "    # 클래스 이름 생성 (색상 기반)\n",
    "    label_to_color = {v: k for k, v in color_to_label.items()}\n",
    "    class_names = [f\"Class {i}\\n{label_to_color[i]}\" for i in range(len(class_ious))]\n",
    "    iou_values = [class_ious[f'class_{i}'] for i in range(len(class_ious))]\n",
    "    \n",
    "    # NaN 값 처리 (해당 클래스가 없는 경우)\n",
    "    iou_values = [0 if np.isnan(v) else v for v in iou_values]\n",
    "    \n",
    "    # 시각화\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.bar(range(len(iou_values)), iou_values, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    \n",
    "    # 값 표시\n",
    "    for i, (bar, val) in enumerate(zip(bars, iou_values)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Class', fontsize=12)\n",
    "    ax.set_ylabel('IoU', fontsize=12)\n",
    "    ax.set_title('IoU per Class', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"클래스별 성능이 '{save_path}'에 저장되었습니다.\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 성능 요약 출력\n",
    "    print(\"\\n클래스별 IoU:\")\n",
    "    print(\"=\"*40)\n",
    "    for i, val in enumerate(iou_values):\n",
    "        print(f\"Class {i} {label_to_color[i]}: {val:.4f}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a978b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 예측 결과 시각화\n",
    "# ============================================\n",
    "\n",
    "def visualize_predictions(model, test_loader, device, label_to_color, num_samples=5, save_path='predictions.png'):\n",
    "    \"\"\"\n",
    "    예측 결과를 원본-정답-예측 형태로 시각화\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 모델\n",
    "        test_loader: 테스트 데이터 로더\n",
    "        device: 디바이스\n",
    "        label_to_color: 라벨-색상 역매핑\n",
    "        num_samples: 시각화할 샘플 수\n",
    "        save_path: 저장할 이미지 경로\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 샘플 가져오기\n",
    "    images, masks = next(iter(test_loader))\n",
    "    \n",
    "    # 실제 배치 크기에 맞춰 샘플 수 조정\n",
    "    actual_samples = min(num_samples, len(images))\n",
    "    if actual_samples < num_samples:\n",
    "        print(f\"  경고: 요청한 샘플 수({num_samples})가 배치 크기({len(images)})보다 큽니다. {actual_samples}개만 시각화합니다.\")\n",
    "    \n",
    "    images = images[:actual_samples].to(device)\n",
    "    masks = masks[:actual_samples].to(device)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(actual_samples, 3, figsize=(12, 4*actual_samples))\n",
    "    if actual_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(actual_samples):\n",
    "        # 원본 이미지\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 정답 마스크 (색상 복원)\n",
    "        gt_mask = masks[i].cpu().numpy()\n",
    "        gt_colored = np.zeros((*gt_mask.shape, 3), dtype=np.uint8)\n",
    "        for label, color in label_to_color.items():\n",
    "            gt_colored[gt_mask == label] = color\n",
    "        \n",
    "        axes[i, 1].imshow(gt_colored)\n",
    "        axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 예측 마스크 (색상 복원)\n",
    "        pred_mask = preds[i].cpu().numpy()\n",
    "        pred_colored = np.zeros((*pred_mask.shape, 3), dtype=np.uint8)\n",
    "        for label, color in label_to_color.items():\n",
    "            pred_colored[pred_mask == label] = color\n",
    "        \n",
    "        axes[i, 2].imshow(pred_colored)\n",
    "        axes[i, 2].set_title('Prediction', fontsize=12, fontweight='bold')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"예측 결과가 '{save_path}'에 저장되었습니다.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee97902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 오버레이 시각화\n",
    "# ============================================\n",
    "\n",
    "def visualize_overlay(model, test_loader, device, label_to_color, num_samples=3, alpha=0.6, save_path='overlay.png'):\n",
    "    \"\"\"\n",
    "    원본 이미지에 예측 마스크를 오버레이하여 시각화\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 모델\n",
    "        test_loader: 테스트 데이터 로더\n",
    "        device: 디바이스\n",
    "        label_to_color: 라벨-색상 역매핑\n",
    "        num_samples: 시각화할 샘플 수\n",
    "        alpha: 오버레이 투명도 (0~1)\n",
    "        save_path: 저장할 이미지 경로\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 샘플 가져오기\n",
    "    images, masks = next(iter(test_loader))\n",
    "    \n",
    "    # 실제 배치 크기에 맞춰 샘플 수 조정\n",
    "    actual_samples = min(num_samples, len(images))\n",
    "    if actual_samples < num_samples:\n",
    "        print(f\"  경고: 요청한 샘플 수({num_samples})가 배치 크기({len(images)})보다 큽니다. {actual_samples}개만 시각화합니다.\")\n",
    "    \n",
    "    images = images[:actual_samples].to(device)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(actual_samples, 2, figsize=(10, 5*actual_samples))\n",
    "    if actual_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(actual_samples):\n",
    "        # 원본 이미지\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 예측 마스크 (색상 복원)\n",
    "        pred_mask = preds[i].cpu().numpy()\n",
    "        pred_colored = np.zeros((*pred_mask.shape, 3), dtype=np.uint8)\n",
    "        for label, color in label_to_color.items():\n",
    "            pred_colored[pred_mask == label] = color\n",
    "        \n",
    "        # 오버레이\n",
    "        overlay = (img * 255).astype(np.uint8)\n",
    "        overlay = cv2.addWeighted(overlay, 1-alpha, pred_colored, alpha, 0)\n",
    "        \n",
    "        axes[i, 1].imshow(overlay)\n",
    "        axes[i, 1].set_title(f'Overlay (alpha={alpha})', fontsize=12, fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"오버레이 결과가 '{save_path}'에 저장되었습니다.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 학습 곡선 및 성능 평가\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"모델 성능 평가 및 시각화 시작\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. 학습 곡선 시각화 (history가 있는 경우)\n",
    "if 'history' in locals():\n",
    "    print(\"\\n학습 곡선 시각화...\")\n",
    "    plot_training_curves(history, save_path='training_curves.png')\n",
    "else:\n",
    "    print(\"\\n경고: history 객체가 없습니다. 학습 곡선을 건너뜁니다.\")\n",
    "\n",
    "# 2. 성능 평가\n",
    "print(\"\\n모델 성능 평가...\")\n",
    "num_classes = len(color_to_label)\n",
    "metrics = evaluate_model(model, test_loader, device, num_classes)\n",
    "\n",
    "print(\"\\n전체 성능:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Pixel Accuracy: {metrics['pixel_accuracy']:.4f}\")\n",
    "print(f\"Mean IoU (mIoU): {metrics['miou']:.4f}\")\n",
    "print(f\"Dice Score: {metrics['dice']:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 3. 클래스별 성능 시각화\n",
    "print(\"\\n클래스별 성능 시각화...\")\n",
    "plot_class_performance(metrics, color_to_label, save_path='class_performance.png')\n",
    "\n",
    "# 4. 예측 결과 시각화 (5개 샘플)\n",
    "print(\"\\n예측 결과 시각화...\")\n",
    "visualize_predictions(model, test_loader, device, label_to_color, num_samples=4, save_path='predictions.png')\n",
    "\n",
    "# 5. 오버레이 시각화 (3개 샘플)\n",
    "print(\"\\n오버레이 시각화...\")\n",
    "visualize_overlay(model, test_loader, device, label_to_color, num_samples=3, alpha=0.6, save_path='overlay.png')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"검증 및 시각화 완료!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08ee96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a908c6e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
